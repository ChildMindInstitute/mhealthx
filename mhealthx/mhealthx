#!/usr/bin/env python
"""
This pipeline runs feature extraction on mHealth data stored on Synapse.org.

Example: mhealthx --phonation syn4590865 -t /home/arno/software/audio

- First-time use on a given machine: include -u and -p for Synapse login.
- Replace -t argument with path to installed feature extraction software.

For help in using mhealthx ::

    - README file
    - Help on the command line::

        $ mhealthx --help

This file uses Nipype (http://www.nipy.org/nipype/) to create a workflow
environment that enables mhealthx to run in a flexible, modular manner
while storing provenance information.

Authors:
    - Arno Klein, 2015  (arno@sagebase.org)  http://binarybottle.com

Copyright 2015,  Sage Bionetworks (http://sagebase.org), Apache v2.0 License

"""

import os
import sys
import argparse
from nipype import config, logging
from nipype.interfaces.io import DataSink
from nipype.interfaces.utility import Function as Fn
from nipype.pipeline.engine import Workflow, Node, JoinNode
from mhealthx.data_io import get_rename_convert_audio, arff_to_csv, \
    concatenate_tables_vertically
from mhealthx.utils import run_command

# ============================================================================
#
# Command-line arguments
#
# ============================================================================
parser = argparse.ArgumentParser(description="""
                    Extract features from mHealth data
                    stored on Sage Bionetwork's Synapse.org.
                    Example: mhealthx --phonation syn4590865 -t /software
                    (-t: path to installed third-party software; -u, -p:
                    Synapse login for first use on a given machine)
""",
                                 formatter_class = lambda prog:
                                 argparse.HelpFormatter(prog,
                                                        max_help_position=40))
parser.add_argument("-v", "--version", help="version number",
                    action='version', version='%(prog)s 0.1')
parser.add_argument("-n", "--numproc",
                    help='number of processors (default: 1)',
                    type=int, default=1, metavar='INT')
parser.add_argument("--stop",
                    help='stop at this many rows of the Synapse tables',
                    type=int, metavar='INT', default=sys.maxint)
parser.add_argument("-g", "--graph",
                    help='plot workflow graph: "hier", "flat", "exec"',
                    choices=['hier', 'flat', 'exec'], metavar='STR')
parser.add_argument("--plugin", dest="plugin",
                    default='Linear',
                    help="optional plugin: --plugin PBS")
parser.add_argument("--plugin_args", dest="plugin_args",
                    help="optional plugin arguments:"
                         " --plugin_args \"dict(qsub_args='-q many')\"")
setup_group = parser.add_argument_group('setup')
setup_group.add_argument("-t", "--thirdparty",
                         help="path to third-party software",
                         metavar='STR')
setup_group.add_argument("-u", "--username",
                         help="Synapse username", metavar='STR')
setup_group.add_argument("-p", "--password",
                         help="Synapse password", metavar='STR')
activities_group = parser.add_argument_group('activities')
activities_group.add_argument("--phonation",
                              help="Synapse table ID for phonation data",
                              metavar='STR')
activities_group.add_argument("--balance",
                              help="Synapse table ID for balance data",
                              metavar='STR')
activities_group.add_argument("--tapping",
                              help="Synapse table ID for tapping data",
                              metavar='STR')
outputs_group = parser.add_argument_group('outputs')
outputs_group.add_argument("-o", "--output",
                           help='output folder (if not $HOME/mhealthx_output)',
                           default=os.path.join(os.environ['HOME'],
                                                'mhealthx_output'),
                           metavar='STR')
outputs_group.add_argument("-c", "--cache",
                           help="cache folder (if not $HOME/mhealthx_cache)",
                           default=os.path.join(os.environ['HOME'],
                                                'mhealthx_cache'),
                           metavar='STR')
outputs_group.add_argument("-i", "--input",
                           help="input (prep) folder "
                                "(if not $HOME/mhealthx_cache/mhealthxprep)",
                           default=os.path.join(os.environ['HOME'],
                                                'mhealthx_cache',
                                                'mhealthxprep'),
                           metavar='STR')
outputs_group.add_argument('--reports', dest='reports', action='store_true',
                           help='generate nipype reports')
outputs_group.set_defaults(reports=False)

args = parser.parse_args()
username = args.username
password = args.password
thirdparty = args.thirdparty
synID_phonation = args.phonation
synID_balance = args.balance
synID_tapping = args.tapping
if args.numproc:
    nproc = args.numproc
else:
    nproc = 1

# ============================================================================
#
# Login once to Synapse and cache credentials
#
# ============================================================================
import synapseclient
syn = synapseclient.Synapse()
syn.login(username, password, rememberMe=True)

# ============================================================================
#
# Initialize main workflow and create output directories
#
# ============================================================================
main_workflow_name = 'mhealthx'
Flow = Workflow(name=main_workflow_name)
Flow.base_dir = args.cache
Sink = Node(DataSink(), name='Results')
Sink.inputs.base_directory = args.output
if not os.path.isdir(args.output):
    print("Create missing output directory: {0}".format(args.output))
    os.makedirs(args.output)
if not os.path.isdir(args.cache):
    print("Create missing cache directory: {0}".format(args.cache))
    os.makedirs(args.cache)
row_path = os.path.join(args.input, 'row_files')
if not os.path.isdir(row_path):
    os.makedirs(row_path)
workflow_path = os.path.join(args.cache, main_workflow_name)
feature_table_file_path = os.path.join(workflow_path, 'feature_tables')
if not os.path.isdir(feature_table_file_path):
    os.makedirs(feature_table_file_path)

# ============================================================================
#
# Phonation workflow
#
# ============================================================================
if synID_phonation:

    # ------------------------------------------------------------------------
    # Retrieve each row + audio file from Synapse table
    # Append file name with ".m4a"
    # Convert voice file to .wav format
    # Copy file with new append:
    # ------------------------------------------------------------------------
    PrepPhonation = Node(name='prepare_phonation_file',
                         interface=Fn(function=get_rename_convert_audio,
                                      input_names=['synapse_table',
                                                   'row',
                                                   'column_name',
                                                   'rename_file_append',
                                                   'convert_file_append',
                                                   'copy_file_append',
                                                   'convert_command',
                                                   'convert_input_args',
                                                   'convert_output_args',
                                                   'out_path,'
                                                   'username',
                                                   'password'],
                                      output_names=['row',
                                                    'converted_file',
                                                    'copy_name']))
    PrepPhonation.inputs.synapse_table = synID_phonation
    row_files = [os.path.join(row_path, f)
                 for i,f in enumerate(sorted(os.listdir(row_path)))
                 if i < args.stop
                 and os.path.isfile(os.path.join(row_path,f))]
    PrepPhonation.iterables = ("row", row_files)
    PrepPhonation.inputs.column_name = 'audio_audio.m4a' #'audio_countdown.m4a'
    PrepPhonation.inputs.rename_file_append = '.m4a'
    PrepPhonation.inputs.convert_file_append = '.wav'
    PrepPhonation.inputs.copy_file_append = '.csv'
    PrepPhonation.inputs.convert_command = 'ffmpeg'
    PrepPhonation.inputs.convert_input_args = '-i'
    PrepPhonation.inputs.convert_output_args = '-ac 2'
    PrepPhonation.inputs.out_path = '.'
    PrepPhonation.inputs.username = ''
    PrepPhonation.inputs.password = ''

    # ------------------------------------------------------------------------
    # Process openSMILE command:
    # ------------------------------------------------------------------------
    OpenSMILE = Node(name='openSMILE',
                     interface=Fn(function=run_command,
                                  input_names=['command',
                                               'flag1',
                                               'arg1',
                                               'flags',
                                               'args',
                                               'flagN',
                                               'argN',
                                               'closing'],
                                  output_names=['command_line',
                                                'args',
                                                'arg1',
                                                'argN']))
    OpenSMILE.inputs.command = 'SMILExtract'
    OpenSMILE.inputs.flag1 = '-I'
    Flow.connect(PrepPhonation, 'converted_file', OpenSMILE, 'arg1')
    OpenSMILE.inputs.flags = '-C'
    OpenSMILE.inputs.args = os.path.join(thirdparty, 'openSMILE-2.1.0',
                                         'config', 'IS13_ComParE.conf')
    OpenSMILE.inputs.flagN = '-O'
    Flow.connect(PrepPhonation, 'copy_name', OpenSMILE, 'argN')
    # Flow.connect(PrepPhonation, ('converted_file', rename_file,
    #                              '', '', '.csv', True), OpenSMILE, 'argN')
    OpenSMILE.inputs.closing = ''

    # ------------------------------------------------------------------------
    # Format openSMILE output and join with metadata:
    # ------------------------------------------------------------------------
    FormatOpenSMILE = Node(name='format_openSMILE_row',
                           interface=Fn(function=arff_to_csv,
                                        input_names=['arff_file',
                                                     'output_csv_file',
                                                     'table_to_join'],
                                        output_names=['table_data',
                                                      'output_csv_file']))
    Flow.connect(OpenSMILE, 'argN', FormatOpenSMILE, 'arff_file')
    FormatOpenSMILE.inputs.output_csv_file = None
    Flow.connect(PrepPhonation, 'row', FormatOpenSMILE, 'table_to_join')

    # ------------------------------------------------------------------------
    # Create a feature table from the original metadata and openSMILE outputs:
    # ------------------------------------------------------------------------
    TableOpenSMILE = JoinNode(name='assemble_openSMILE_table',
                              joinsource=PrepPhonation,
                              joinfield=['tables'],
                              interface=Fn(function=
                                           concatenate_tables_vertically,
                                           input_names=['tables',
                                                        'output_csv_file'],
                                           output_names=['table_data',
                                                         'output_csv_file']))
    Flow.connect(FormatOpenSMILE, 'table_data', TableOpenSMILE, 'tables')
    TableOpenSMILE.inputs.output_csv_file = os.path.join(
        feature_table_file_path,
        'phonation_features_openSMILE_IS13_ComParE.csv')
    Flow.connect(TableOpenSMILE, 'output_csv_file',
                 Sink, 'feature_tables.@openSMILE')



    # ------------------------------------------------------------------------
    # Store openSMILE features to its own Synapse table:
    # ------------------------------------------------------------------------
    # SaveOpenSMILE = JoinNode(name='save_openSMILE',
    #                          joinsource='OpenSMILE',
    #                          joinfield='dataframes',
    #                          interface=Fn(function=dataframes_to_csv_file,
    #                                       input_names=['dataframes',
    #                                                    'csv_file'],
    #                                       output_names=['table_data',
    #                                                     'csv_file']))
    # Flow.connect(FormatOpenSMILE, 'feature_table',
    #              SaveOpenSMILE, 'dataframes')
    # SaveOpenSMILE.inputs.csv_file = 'openSMILE_IS13_ComParE.csv'
    # Flow.connect(SaveOpenSMILE, 'csv_file', Sink, 'phonation.@features')

    # ------------------------------------------------------------------------
    # Store openSMILE features to its own Synapse table:
    # FIX: WOULD NEED TO REORGANIZE: | feature | statistical summary | value |
    # ------------------------------------------------------------------------
    # SaveOpenSMILE = Node(name='save_openSMILE',
    #              interface=Fn(function=concatenate_tables_to_synapse_table,
    #                           input_names=['tables',
    #                                        'synapse_project_id',
    #                                        'table_name',
    #                                        'username',
    #                                        'password'],
    #                           output_names=['table_data',
    #                                         'table_name',
    #                                         'synapse_table_id',
    #                                         'synapse_project_id']))
    # Flow.connect(FormatOpenSMILE, 'feature_table', SaveOpenSMILE, 'tables')
    # SaveOpenSMILE.inputs.synapse_project_id = 'syn4899451'
    # SaveOpenSMILE.inputs.table_name = 'Phonation openSMILE feature table'
    # SaveOpenSMILE.inputs.username = ''
    # SaveOpenSMILE.inputs.password = ''

    # ------------------------------------------------------------------------
    # Store openSMILE output file handle to the mPower phonation file table:
    # ------------------------------------------------------------------------
    # StoreOpenSMILE = Node(name='store_openSMILE',
    #                       interface=Fn(function=file_to_synapse_table,
    #                                    input_names=['feature_file',
    #                                                 'raw_feature_file',
    #                                                 'source_file_id',
    #                                                 'provenance_activity_id',
    #                                                 'command_line',
    #                                                 'synapse_table_id',
    #                                                 'username',
    #                                                 'password'],
    #                                    output_names=[]))
    # Flow.connect(SaveOpenSMILE, 'csv_file',
    #              StoreOpenSMILE, 'feature_file')
    # Flow.connect(OpenSMILE, 'argN',
    #              StoreOpenSMILE, 'raw_feature_file')
    # StoreOpenSMILE.inputs.provenance_activity_id = ''
    # #Flow.connect(OpenSMILE, 'argN',
    # #             StoreOpenSMILE, 'source_file_id')
    # StoreOpenSMILE.inputs.source_file_id = ''
    # Flow.connect(OpenSMILE, 'command_line',
    #              StoreOpenSMILE, 'command_line')
    # Flow.connect(PrepPhonation, 'synapse_table_id',
    #              StoreOpenSMILE, 'synapse_table_id')
    # StoreOpenSMILE.inputs.username = ''
    # StoreOpenSMILE.inputs.password = ''


# ============================================================================
#
# Run workflows
#
# ============================================================================
if __name__ == '__main__':

    from time import time
    time0 = time()

    # ------------------------------------------------------------------------
    # Workflow configuration: provenance tracking, content hashing, etc.:
    # ------------------------------------------------------------------------
    # config.enable_provenance()
    Flow.config['execution']['hash_method'] = 'timestamp'
    Flow.config['execution']['local_hash_check'] = False
    Flow.config['execution']['create_report'] = args.reports

    # ------------------------------------------------------------------------
    # Generate a visual graph:
    # ------------------------------------------------------------------------
    graph_vis = args.graph
    if graph_vis:
        if graph_vis == 'exec':
            Flow.write_graph(graph2use=graph_vis, simple_form=False)
        else:
            if graph_vis == 'hier':
                graph_vis = 'hierarchical'
            Flow.write_graph(graph2use=graph_vis)

    # ------------------------------------------------------------------------
    # Debug: http://nipy.org/nipype/users/config_file.html#debug-configuration
    # ------------------------------------------------------------------------
    debug = False
    if debug:
        config.set('logging', 'workflow_level', 'DEBUG')
        logging.update_logging(config)
        Flow.config['execution']['stop_on_first_rerun'] = True
        nproc = 1

    # ------------------------------------------------------------------------
    # Run with or without a plugin:
    # Ex: workflow.run(plugin='SGEGraph',
    #                  plugin_args = {'dont_resubmit_completed_jobs': True})
    # ------------------------------------------------------------------------
    if args.plugin:
        if args.plugin_args:
            Flow.run(plugin=args.plugin, plugin_args=eval(args.plugin_args))
        else:
            Flow.run(plugin=args.plugin)
    elif nproc > 1:
        Flow.run(plugin='MultiProc',
                 plugin_args={'n_procs': nproc})
    else:
        Flow.run()  # Use all processors: Flow.run(plugin='MultiProc')

    print('Done! ({0:0.2f} seconds)'.format(time() - time0))

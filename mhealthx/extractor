#!/usr/bin/env python
"""
This pipeline runs feature extraction on mHealth data stored on Synapse.org.

For help in using extractor ::

    - README file
    - Help on the command line::

        $ extractor --help

This file uses Nipype (http://www.nipy.org/nipype/) to create a workflow
environment that enables extractor to run in a flexible, modular manner
while storing provenance information.

Authors:
    - Arno Klein, 2015  (arno@sagebase.org)  http://binarybottle.com

Copyright 2015,  Sage Bionetworks (http://sagebase.org), Apache v2.0 License

"""

import os
import argparse
from nipype import config, logging
from nipype.interfaces.io import DataSink
from nipype.interfaces.utility import Function as Fn
from nipype.pipeline.engine import Workflow, Node
from mhealthx.io_data import read_synapse_table_files, append_file_names, \
                             convert_audio_files
from mhealthx.features import opensmile

# ============================================================================
#
# Command-line arguments
#
# ============================================================================
parser = argparse.ArgumentParser(description="""
                    Extract features from mHealth data
                    stored on Sage Bionetwork's Synapse.org.""",
                    formatter_class = lambda prog:
                    argparse.HelpFormatter(prog, max_help_position=40))
parser.add_argument("-v", "--version", help="version number",
                    action='version', version='%(prog)s 0.1')
parser.add_argument("-n", "--numproc",
                    help=('number of processors (default: 1)'),
                    type=int, default=1, metavar='INT')
parser.add_argument("-g", "--graph",
                    help=('plot workflow graph: "hier", "flat", "exec"'),
                    choices=['hier', 'flat', 'exec'], metavar='STR')
parser.add_argument("--plugin", dest="plugin",
                    default='Linear',
                    help="optional plugin: --plugin PBS")
parser.add_argument("--plugin_args", dest="plugin_args",
                    help="optional plugin arguments:"
                         " --plugin_args \"dict(qsub_args='-q many')\"")
setup_group = parser.add_argument_group('setup')
setup_group.add_argument("-t", "--thirdparty",
                    help="path to third-party software",
                    metavar='STR')
setup_group.add_argument("-u", "--username",
                    help="Synapse username",
                    metavar='STR')
setup_group.add_argument("-p", "--password",
                    help="Synapse password",
                    metavar='STR')
activities_group = parser.add_argument_group('activities')
activities_group.add_argument("--phonation",
                    help="Synapse table ID for phonation data",
                    metavar='STR')
activities_group.add_argument("--balance",
                    help="Synapse table ID for balance data",
                    metavar='STR')
activities_group.add_argument("--tapping",
                    help="Synapse table ID for tapping data",
                    metavar='STR')
outputs_group = parser.add_argument_group('outputs')
outputs_group.add_argument("-o", "--output",
                    help='output folder (if not $HOME/mhealthx_output)',
                    default=os.path.join(os.environ['HOME'],
                                         'mhealthx_output'), metavar='STR')
outputs_group.add_argument("-c", "--cache",
                    help="cache folder"
                         " (if not $HOME/mhealthx_cache)",
                    default=os.path.join(os.environ['HOME'],
                                         'mhealthx_cache'), metavar='STR')
args = parser.parse_args()
username = args.username
password = args.password
thirdparty = args.thirdparty
synID_phonation = args.phonation
synID_balance = args.balance
synID_tapping = args.tapping
if args.numproc:
    nproc = args.numproc
else:
    nproc = 1

# ============================================================================
#
# Login once to Synapse and cache credentials
#
# ============================================================================
import synapseclient
syn = synapseclient.Synapse()
syn.login(username, password, rememberMe=True)

# ============================================================================
#
# Initialize main workflow and create output directories
#
# ============================================================================
main_workflow_name = 'mHealthX'
Flow = Workflow(name=main_workflow_name)
Flow.base_dir = args.cache
Sink = Node(DataSink(), name='Results')
Sink.inputs.base_directory = args.output
if not os.path.isdir(args.output):
    print("Create missing output directory: {0}".format(args.output))
    os.makedirs(args.output)
if not os.path.isdir(args.cache):
    print("Create missing cache directory: {0}".format(args.cache))
    os.makedirs(args.cache)
if synID_phonation:
    phonation_file_path = os.path.join(args.cache, main_workflow_name,
                                       'phonation_files')
    if not os.path.isdir(phonation_file_path):
        os.makedirs(phonation_file_path)

# ============================================================================
#
# Phonation workflow
#
# ============================================================================
if synID_phonation:
    phonFlow = Workflow(name='phonation')

    # ------------------------------------------------------------------------
    # Read Synapse table:
    # ------------------------------------------------------------------------
    GetPhonationFiles = Node(name='get_phonation_files',
                             interface=Fn(function=read_synapse_table_files,
                                          input_names=['synapse_table_ID',
                                                       'username',
                                                       'password',
                                                       'column_name',
                                                       'select_rows',
                                                       'output_path'],
                                          output_names=['dataframe',
                                                        'files']))
    Flow.add_nodes([GetPhonationFiles])
    GetPhonationFiles.inputs.synapse_table_ID = synID_phonation
    GetPhonationFiles.inputs.username = '' #username
    GetPhonationFiles.inputs.password = '' #password
    GetPhonationFiles.inputs.column_name = 'audio_audio.m4a'
    GetPhonationFiles.inputs.select_rows = range(3) #[]
    GetPhonationFiles.inputs.output_path = phonation_file_path

    # ------------------------------------------------------------------------
    # Append file names with ".m4a":
    # ------------------------------------------------------------------------
    RenamePhonationFiles = Node(name='rename_phonation_files',
                                interface=Fn(function=append_file_names,
                                             input_names=['input_files',
                                                          'file_append'],
                                             output_names=['output_files']))
    Flow.add_nodes([RenamePhonationFiles])
    Flow.connect(GetPhonationFiles, 'files',
                 RenamePhonationFiles, 'input_files')
    RenamePhonationFiles.inputs.file_append = '.m4a'

    # ------------------------------------------------------------------------
    # Convert voice files to .wav format:
    # ------------------------------------------------------------------------
    ConvertPhonationFiles = Node(name='convert_phonation_files',
                                 interface=Fn(function=convert_audio_files,
                                              input_names=['input_files',
                                                           'file_append',
                                                           'command'],
                                              output_names=['output_files']))
    Flow.add_nodes([ConvertPhonationFiles])
    Flow.connect(RenamePhonationFiles, 'output_files',
                 ConvertPhonationFiles, 'input_files')
    ConvertPhonationFiles.inputs.file_append = '.wav'
    ConvertPhonationFiles.inputs.command = os.path.join(thirdparty,
                                                        'libav', 'avconv')

    #-------------------------------------------------------------------------
    # Run openSMILE feature extraction on voice data:
    #-------------------------------------------------------------------------
    RunOpenSMILE = Node(name='openSMILE',
                        interface=Fn(function=opensmile,
                                     input_names=['input_files',
                                                  'config_file',
                                                  'output_append',
                                                  'command'],
                                     output_names=['feature_table']))
    Flow.add_nodes([RunOpenSMILE])
    Flow.connect(ConvertPhonationFiles, 'output_files',
                 RunOpenSMILE, 'input_files')
    RunOpenSMILE.inputs.config_file = os.path.join(thirdparty,
                                                   'openSMILE','conf',
                                                   'IS13_ComParE.conf')
    RunOpenSMILE.inputs.output_append = '.csv'
    RunOpenSMILE.inputs.command = os.path.join(thirdparty,
                                               'openSMILE','SMILExtract')
    Flow.connect(RunOpenSMILE, 'feature_table',
                 Sink, 'phonation.@features.openSMILE')

# ============================================================================
#
# Run workflows
#
# ============================================================================
if __name__ == '__main__':

    from time import time
    time0 = time()

    # ------------------------------------------------------------------------
    # Workflow configuration: provenance tracking, content hashing, etc.:
    # ------------------------------------------------------------------------
    # config.enable_provenance()
    Flow.config['execution']['hash_method'] = 'content'
    # Flow.config['execution']['use_relative_paths'] = True

    # ------------------------------------------------------------------------
    # Generate a visual graph:
    # ------------------------------------------------------------------------
    graph_vis = args.graph
    if graph_vis:
        if graph_vis == 'exec':
            Flow.write_graph(graph2use=graph_vis, simple_form=False)
        else:
            if graph_vis == 'hier':
                graph_vis = 'hierarchical'
            Flow.write_graph(graph2use=graph_vis)

    # ------------------------------------------------------------------------
    # Debug: http://nipy.org/nipype/users/config_file.html#debug-configuration
    # ------------------------------------------------------------------------
    debug = False
    if debug:
        config.set('logging', 'workflow_level', 'DEBUG')
        logging.update_logging(config)
        Flow.config['execution']['stop_on_first_rerun'] = True
        nproc = 1

    # ------------------------------------------------------------------------
    # Run with or without a plugin:
    # ------------------------------------------------------------------------
    if args.plugin:
        if args.plugin_args:
            Flow.run(plugin=args.plugin, plugin_args=eval(args.plugin_args))
        else:
            Flow.run(plugin=args.plugin)
    elif nproc > 1:
        Flow.run(plugin='MultiProc',
                 plugin_args={'n_procs': nproc})
    else:
        Flow.run()  # Use all processors: Flow.run(plugin='MultiProc')

    print('Done! ({0:0.2f} seconds)'.format(time() - time0))

#!/usr/bin/env python
"""
This is the main program to run feature extraction of mHealth data on Synapse.

For help in using extractor ::

    - README file
    - Help on the command line::

        $ extractor --help

This file uses Nipype (http://www.nipy.org/nipype/) to create a workflow
environment that enables extractor to run in a flexible, modular manner
while storing provenance information.

Authors:
    - Arno Klein, 2015  (arno@sagebase.org)  http://binarybottle.com

Copyright 2015,  Sage Bionetworks (http://sagebase.org), Apache v2.0 License

"""

import os
import argparse
from nipype import config, logging
from nipype.interfaces.io import DataGrabber, DataSink
from nipype.interfaces.utility import Function as Fn
from nipype.interfaces.utility import IdentityInterface
from nipype.pipeline.engine import Workflow, Node
from io_data import read_synapse_table, write_synapse_table #, \
                    #get_synapse_file

#=============================================================================
#
#   Command-line arguments
#
#=============================================================================
parser = argparse.ArgumentParser(description="""
                    The extractor software extracts features from mHealth
                    data stored on Sage Bionetwork's Synapse.org.""",
                     formatter_class = lambda prog:
                     argparse.HelpFormatter(prog, max_help_position=40))
parser.add_argument("-n", "--numproc",
                    help=('number of processors (default: 1)'),
                    type=int, default=1, metavar='INT')
parser.add_argument("-g", "--graph",
                    help=('plot workflow graph: "hier", "flat", "exec"'),
                    choices=['hier', 'flat', 'exec'], metavar='STR')
parser.add_argument("-v", "--version", help="extractor version number",
                    action='version', version='%(prog)s 0.1')
parser.add_argument("--plugin", dest="plugin",
                    default='Linear',
                    help="Plugin to use, such as: --plugin PBS")
parser.add_argument("--plugin_args", dest="plugin_args",
                    help="Plugin arguments in dictionary form, such as:"
                         " --plugin_args \"dict(qsub_args='-q many')\"")
login_group = parser.add_argument_group('Synapse login')
login_group.add_argument("-e", "--email",
                    help="email address to access Synapse project",
                    metavar='STR')
login_group.add_argument("-p", "--password",
                    help="password to access Synapse project",
                    metavar='STR')
activities_group = parser.add_argument_group('activities')
activities_group.add_argument("--phonation",
                    help="Synapse ID for phonation data table"
                         " (to run phonation feature extraction)",
                    metavar='STR')
activities_group.add_argument("--balance",
                    help=(argparse.SUPPRESS),
#                    help="Synapse ID for balance data table"
#                         " (to run balance feature extraction)",
                    metavar='STR')
activities_group.add_argument("--tapping",
                    help=(argparse.SUPPRESS),
#                    help="Synapse ID for tapping data table"
#                         " (to run tapping feature extraction)",
                    metavar='STR')
outputs_group = parser.add_argument_group('modify outputs')
outputs_group.add_argument("--output",
                    help='output folder (if not $HOME/mhealthx_output)',
                    default=os.path.join(os.environ['HOME'],
                                         'mhealthx_output'), metavar='STR')
outputs_group.add_argument("--working",
                    help="working folder"
                         " (if not $HOME/mhealthx_working)",
                    default=os.path.join(os.environ['HOME'],
                                         'mhealthx_working'), metavar='STR')
args = parser.parse_args()
synapse_email = args.email
synapse_password = args.password
synID_phonation = args.phonation
synID_balance = args.balance
synID_tapping = args.tapping

#=============================================================================
#
#   Initialize main workflow and create output directories
#
#=============================================================================
Flow = Workflow(name='mHealthX')
Flow.base_dir = args.working
Sink = Node(DataSink(), name='Results')
Sink.inputs.base_directory = args.output
#Sink.inputs.container =
if not os.path.isdir(args.output):
    print("Create missing output directory: {0}".format(args.output))
    os.makedirs(args.output)
if not os.path.isdir(args.working):
    print("Create missing working directory: {0}".format(args.working))
    os.makedirs(args.working)

#=============================================================================
#
#   Phonation workflow
#
#=============================================================================
if synID_phonation:
    phonFlow = Workflow(name='Phonation')

    #-------------------------------------------------------------------------
    # Read Synapse table:
    #-------------------------------------------------------------------------
    GetPhonationTable = Node(name='get_phonation_table',
                             interface=Fn(function=read_synapse_table,
                                          input_names=['synapse_table_ID',
                                                       'synapse_email',
                                                       'synapse_password'],
                                          output_names=['dataframe']))
    Flow.add_nodes([GetPhonationTable])
    GetPhonationTable.inputs.synapse_table_ID = synID_phonation
    GetPhonationTable.inputs.synapse_email = synapse_email
    GetPhonationTable.inputs.synapse_password = synapse_password

    #-------------------------------------------------------------------------
    # Retrieve voice file in table:
    #-------------------------------------------------------------------------
    GetPhonationFile = Node(name='get_phonation_file',
                            interface=Fn(function=get_synapse_file,
                                         input_names=['dataframe',
                                                      'synapse_email',
                                                      'synapse_password'],
                                         output_names=['file']))
    Flow.add_nodes([GetPhonationFile])
    Flow.connect(GetPhonationTable, 'dataframe',
                 GetPhonationFile, 'dataframe')
    GetPhonationFile.inputs.synapse_email = synapse_email
    GetPhonationFile.inputs.synapse_password = synapse_password
    Flow.connect(GetPhonationFile, 'file', Sink, 'phonation.@m4a_file')

    # #-------------------------------------------------------------------------
    # # Convert voice file from M4A (AAC) to WAV format:
    # #-------------------------------------------------------------------------
    # ConvertPhonationFile = Node(name='convert_phonation_file',
    #                         interface=Fn(function=m4a_to_wav,
    #                                      input_names=['m4a_file'],
    #                                      output_names=['wav_file']))
    # Flow.add_nodes([ConvertPhonationFile])
    # Flow.connect(GetPhonationFile, 'file',
    #              ConvertPhonationFile, 'm4a_file')
    # Flow.connect(ConvertPhonationFile, 'wav_file',
    #              Sink, 'phonation.@wav_file')
    #
    # #-------------------------------------------------------------------------
    # # Run openSMILE feature extraction on voice data:
    # #-------------------------------------------------------------------------
    # RunOpenSMILE = Node(name='openSMILE',
    #                     interface=Fn(function=run_openSMILE,
    #                                  input_names=['wav_file'],
    #                                  output_names=['features']))
    # Flow.add_nodes([RunOpenSMILE])
    # Flow.connect(ConvertPhonationFile, 'wav_file',
    #              RunOpenSMILE, 'wav_file')
    # Flow.connect(RunOpenSMILE, 'features',
    #              Sink, 'phonation.@features.openSMILE')

#=============================================================================
#
#   Run workflows
#
#=============================================================================
if __name__ == '__main__':

    from time import time
    time0 = time()
    #-------------------------------------------------------------------------
    # Set the workflow configuration enable provenance tracking:
    #-------------------------------------------------------------------------
    #config.enable_provenance()

    #-------------------------------------------------------------------------
    # Set the workflow configuration to use content hashing:
    #-------------------------------------------------------------------------
    Flow.config['execution']['hash_method'] = 'content'
    #hashing = args.hashing
    #if hashing:
    #Flow.config['execution']['hash_method'] = 'content'
    #Flow.config['execution']['use_relative_paths'] = True

    #-------------------------------------------------------------------------
    # Generate a visual graph:
    #-------------------------------------------------------------------------
    graph_vis = args.graph
    if graph_vis == 'hier':
        graph_vis = 'hierarchical'
    if graph_vis:
        if graph_vis == 'exec':
            Flow.write_graph(graph2use=graph_vis, simple_form=False)
        else:
            Flow.write_graph(graph2use=graph_vis)

    #-------------------------------------------------------------------------
    # Debug: http://nipy.org/nipype/users/config_file.html#debug-configuration
    #-------------------------------------------------------------------------
    debug = False
    if debug:
        config.set('logging', 'workflow_level', 'DEBUG')
        logging.update_logging(config)
        Flow.config['execution']['stop_on_first_rerun'] = True
        nproc = 1
    else:
        if args.numproc:
            nproc = args.numproc
        else:
            nproc = 1

    #-------------------------------------------------------------------------
    # Run plugin, such as for multiple processes:
    #-------------------------------------------------------------------------
    if args.plugin:
        if args.plugin_args:
            Flow.run(args.plugin, plugin_args=eval(args.plugin_args))
        else:
            Flow.run(args.plugin)
    if args.numproc:
        if nproc > 1:
            Flow.run(plugin='MultiProc',
                       plugin_args={'n_procs': args.numproc})
                       #updatehash=True)
        else:
            Flow.run()  #updatehash=True)
    else:
        Flow.run()  #updatehash=True)
    # # Default is to use all processors:
    #else:
    #    Flow.run(plugin='MultiProc')

    print('extractor run finished ({0:0.2f} seconds).'.format(time() - time0))
